### 범주

인공지능 > 머신러닝 > 딥러닝


# 필수 라이브러리

numpy

pandas

matplotlib, seaborn, folium

scikit-learn

tensorflow, keras, pytorch

# 머신러닝
목표를 결정 -> 데이터 수집 -> 데이터 전처리 -> 머신러닝 모델 선택 -> 학습 -> 평가 -> 적용


자체평가를 하기 위해서 데이터를 나눈다.
- 데이터 셋(하나)
- 학습을 위한 학습 데이터 train
- 테스트를 위한 테스트 데이터 test
  (자체 평가) - 출력
   x1 x2 x3 x4 y(target)

   x1 x2 x3 x4 y(target)
   
   train_test_split()

   test_size : 테스트 데이터 셋의 비율
   기본 비율 : 75%(학습용), 25%(테스트용)
   지정된 열도 동일한 비율로 나누는 매개 변수는 무엇일까요 ?   stratify없ㅇ
   


# 캐글의 경우

train

  학습용  : 학습 

  테스트용 : 자체 평가

test (target이 없음 - 평가는 제출해야 가능)

########### 


# 머신러닝 구분

A. 지도학습 :  훈련 데이터의 입력과 target 사이에 있는 관계를 학습 

           대부분 분류와 회귀로 구성

           (ex: 광학문자 판독, 음성 인식, 이미지분류, 언어 번역)


B. 비지도학습: 어떤 target도 사용하지 않고 입력 데이터에 대한 흥미로운 변환을 찾음   

           데이터 시각화, 데이터 압축, 데이터의 노이즈 제거 또는 데이터에 있는 상관관계를 더 잘 이해하기 위해 사용



C. 지도학습과 비지도학습의 차이

- 지도학습은 target 값이 있고,
- 비지도학습은 target 값이 없다.

# 지도학습

  - 회귀(Regression)
     - 예측하고자 하는 target값이 연속형

  - 분류(Classificatio)
     - 예측하고자 하는 target값이 범주형 
         A. 이진분류 - 범주형의 범주의 개수가 2개
         B. 다중분류 - 범주형의 범주의 개수가 3개 이상 

 
# 과적합 or 과대적합(overfitting)

  - 학습한 것에만 딱 맞게 학습한 것.

  - 학습 데이터에만 성능이 최적화되어서, 일반적인 다른 데이터는 잘 최적화되어 있지 않다.

  

# 과소적합(underfitting)

과대적합(overfitting)의 현상

# knn 모델 (k-Nearest Neighbors) 
  내용 : 데이터포인트와 가장 가까운 k개의 데이터를 찾아서 k개 데이터가 가장 많이 예측하는 다수 또는 평균으로 예측하는 
  (하이퍼 파라미터 : 사용자가 지정한다.)

  - [분류] 새로운 데이터와 기존데이터 거리 가까운 것.(k=3)이면 세개의 데이터의 target의 값이 많은 값으로 분류하게 된다.

  - [회귀] 새로운 데이터와의 거리에 따라서 k가 3이라고 하면, 세개의 값의 target의 값의 평균으로 예측하는 모델


# 의사결정트리 : 분류와 회귀 문제에 널리 사용하는 모델
                (앙상블 기본 요소로 사용)

  - 구성 : 루트노드, 리프노드, Decision node
           트리의 깊이 단점 : 과대적합, 과소적합.
  - 분류
  - 회귀
  - 노드가 분기하는 조건을 결정
    - 분류 : 지니계수와 엔트로피를 사용
    - 회귀 : MSE 사용

# 앙상블 모델
  - 앙상블 여러 머신러닝 모델을 연결하여 더 강력한 모델을 만든다.
  - (A) Random Forest
        : 결정트리의 주요 단점인 과대적합을 극복하기 위해 등장   
        : 약간씩 다른 여러 개의 트리를 사용 -> 데이터를(중복 복원 추출), 변수를 조금씩 다르게 한다.
       - 예측
        : (분류) 10개의 트리가 예측하는 값의 다수로 예측
        : (연속) 10개의 트리가 예측하는 값(target)의 평균으로 예측

  - (B) Gradient boosting

# 선형 회귀(Linear Regression)

  - 선형 함수로 표현이 된다.
  - target 값이 연속형일때 이 모델을 사용.
  - y = w1 * x1 + b (특징 하나)
  - w1(회귀계수), b(편향) 이 친구들이 결정된다.
  - MSE의 값이 최소가 되는 w,b의 값이 결정된다.

  - 특징 하나 - 직선, 특징이 두개 - 평면, 특징이 세개 이상- 초평면으로 표현된다.

  - 선형모델에서 MSE가 최소가 되는 w, b가 정해진다. 

     w : 회귀계수(가중치), b : 편향.


